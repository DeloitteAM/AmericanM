{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Import Libraries ####################################\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import configparser\n",
    "import cx_Oracle\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,  plot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Constants ######################################################\n",
    "num_std_dev = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Read INI File ###############################\n",
    "ini_path = 'C:\\\\Users\\\\dmiglani\\\\Desktop\\\\ModernAmerican\\\\config_modern_am_oracle.ini'\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(ini_path)\n",
    "\n",
    "proj_path = config['PATH']['Project Directory']\n",
    "\n",
    "host = config['Oracle_Connect']['Host']\n",
    "port = config['Oracle_Connect']['Port']\n",
    "db = config['Oracle_Connect']['Database']\n",
    "user = config['Oracle_Connect']['User_ID']\n",
    "pwd = config['Oracle_Connect']['Password']\n",
    "\n",
    "del config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Import functions ############################\n",
    "os.chdir(proj_path + '/04.Codes/Functions')\n",
    "from preprocess import column_preprocess\n",
    "os.chdir(proj_path)\n",
    "\n",
    "intermediate_dir_path = proj_path + \"/05.Intertmediate/Pekin/\"\n",
    "del proj_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Established\n"
     ]
    }
   ],
   "source": [
    "################################## Connect to oracle DB #######################\n",
    "# conn_str = user + \"/\" + pwd + \"@\" + host + \":\" + port + \"/\" + db\n",
    "conn_str = 'ClAIMUSER' + \"/\" + pwd + \"@\" + host + \":\" + port + \"/\" + 'CCDatabase'\n",
    "conn = cx_Oracle.connect(conn_str)\n",
    "print(\"Connection Established\")\n",
    "del host, port, db, user, pwd, conn_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Read Oracle DB #######################################\n",
    "read_db_path = '04.Codes/read_db.py'\n",
    "exec(compile(open(read_db_path, \"rb\").read(), read_db_path, 'exec'))\n",
    "\n",
    "print(\"Datatables Imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc_claim = cc_claim2.copy()\n",
    "# cc_Incident = cc_Incident2.copy()\n",
    "# cc_transaction = cc_transaction2.copy()\n",
    "# cc_activity = cc_activity2.copy()\n",
    "# cctl_incident = cctl_incident2.copy()\n",
    "# cc_address = cc_address2.copy()\n",
    "# cc_policy = cc_policy2.copy()\n",
    "# cc_check = cc_check2.copy()\n",
    "# cc_exposure = cc_exposure2.copy()\n",
    "# cc_contact = cc_contact2.copy()\n",
    "# cc_claimcontact = cc_claimcontact2.copy()\n",
    "# cctl_losscause = cctl_losscause2.copy()\n",
    "# cc_transactionlineitem = cc_transactionlineitem2.copy()\n",
    "# cc_reserveline = cc_reserveline2.copy()\n",
    "# cc_user = cc_user2.copy()\n",
    "# cc_authorityprofile = cc_authorityprofile2.copy()\n",
    "# cc_authoritylimit = cc_authoritylimit2.copy()\n",
    "# cctl_authoritylimittype = cctl_authoritylimittype2.copy()\n",
    "# cctl_userexperiencetype = cctl_userexperiencetype2.copy()\n",
    "# cc_checkpayee = cc_checkpayee2.copy() \n",
    "# cc_claimIndicator = cc_claimIndicator2.copy()\n",
    "# cc_userregion = cc_userregion2.copy()\n",
    "# cc_region = cc_region2.copy()\n",
    "# cc_region_zone =cc_region_zone2.copy()\n",
    "# cc_catastrophezone = cc_catastrophezone2.copy()\n",
    "# cctl_zonetype = cctl_zonetype2.copy()\n",
    "# cc_catastrophe = cc_catastrophe2.copy()\n",
    "# cctl_catastrophetype = cctl_catastrophetype2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Select desired columns #####################################\n",
    "cc_claim = cc_claim[['ID','REPORTEDDATE','LITIGATIONSTATUS', 'LOSSCAUSE', \n",
    "                     'LOSSDATE', 'ASSIGNEDUSERID', 'INSUREDDENORMID', \n",
    "                     'CLAIMNUMBER', 'POLICYID', 'LOSSTYPE', 'LOSSLOCATIONID',\n",
    "                     'CATASTROPHEID', 'LOBCODE', 'STATE']]\n",
    "\n",
    "cc_address = cc_address[['ID', 'ADDRESSLINE1', 'ADDRESSLINE2', 'STATE', 'CITY', \n",
    "                         'POSTALCODE']]\n",
    "\n",
    "cc_policy = cc_policy[['ID', 'REPORTINGDATE', 'EFFECTIVEDATE', 'EXPIRATIONDATE', \n",
    "                       'POLICYNUMBER']]\n",
    "\n",
    "cc_check = cc_check[['ID', 'CLAIMID', 'PAYTO', 'REPORTABLEAMOUNT', 'PAYMENTMETHOD', \n",
    "                     'CLAIMCONTACTID']]\n",
    "\n",
    "cc_exposure = cc_exposure[['ID','COVERAGEID', 'EXAMINATIONDATE', \n",
    "                           'DEPRECIATEDVALUE', 'INCIDENTID', 'REPLACEMENTVALUE', \n",
    "                           'LOSTPROPERTYTYPE', 'CREATETIME', 'CLAIMID',\n",
    "                           'CLAIMANTDENORMID']]\n",
    "\n",
    "cc_contact = cc_contact[['TAXID', 'ID', 'LASTNAME', 'FIRSTNAME', \n",
    "                         'EMPLOYEENUMBER', 'NAME','GREENCARDNUMBER',\n",
    "                         'PRIMARYADDRESSID', 'ADDRESSBOOKUID']]\n",
    "\n",
    "cc_claimcontact = cc_claimcontact[['ID', 'CONTACTID']]\n",
    "\n",
    "cctl_losscause = cctl_losscause[['ID', 'DESCRIPTION']]\n",
    "\n",
    "cc_checkpayee = cc_checkpayee[['ID', 'CHECKID', 'PAYEEDENORMID', 'CLAIMCONTACTID']]\n",
    "\n",
    "cc_activity = cc_activity[['CLAIMID', 'CREATETIME', 'UPDATEUSERID']]\n",
    "\n",
    "cc_user = cc_user[['ID','AUTHORITYPROFILEID', 'EXPERIENCELEVEL']]\n",
    "\n",
    "cc_authoritylimit = cc_authoritylimit[['PROFILEID', 'LIMITAMOUNT', 'LIMITTYPE']]\n",
    "\n",
    "cc_claimIndicator = cc_claimIndicator[['CLAIMID', 'SUBTYPE', 'ISON']]\n",
    "\n",
    "cctl_userexperiencetype = cctl_userexperiencetype[['ID', 'NAME']]\n",
    "\n",
    "cc_catastrophe = cc_catastrophe[['ID', 'TYPE', 'CATASTROPHEVALIDFROM',\n",
    "                                 'CATASTROPHEVALIDTO']]\n",
    "cctl_catastrophetype = cctl_catastrophetype[['ID', 'NAME']]\n",
    "\n",
    "cc_catastrophezone = cc_catastrophezone[['ID', 'CATASTROPHEID', 'COUNTRY', \n",
    "                                         'ZONETYPE']]\n",
    "\n",
    "cctl_zonetype = cctl_zonetype[['ID', 'NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Filter tables ############################################\n",
    "cc_claim = cc_claim.loc[cc_claim['STATE'] != 1] #Remove Draft Claims\n",
    "\n",
    "###Filter HO claims\n",
    "#cc_claim = cc_claim.loc[cc_claim['LOBCODE'] == 10005] \n",
    "\n",
    "cc_check = cc_check.loc[cc_check.CLAIMID.isin(cc_claim.ID)]\n",
    "cc_exposure = cc_exposure.loc[cc_exposure.CLAIMID.isin(cc_claim.ID)]\n",
    "cc_activity = cc_activity.loc[cc_activity.CLAIMID.isin(cc_claim.ID)]\n",
    "cc_claimIndicator = cc_claimIndicator.loc[\n",
    "        cc_claimIndicator.CLAIMID.isin(cc_claim.ID)]\n",
    "\n",
    "\n",
    "#Filter Payment Limit\n",
    "cc_authoritylimit = cc_authoritylimit.loc[cc_authoritylimit['LIMITTYPE'] == 2] \n",
    "cc_authoritylimit = cc_authoritylimit.drop(columns = ['LIMITTYPE'])\n",
    "\n",
    "#Filter  Severeity Indicator Flag \n",
    "cc_claimIndicator = cc_claimIndicator.loc[cc_claimIndicator['SUBTYPE'] == 4]\n",
    "cc_claimIndicator = cc_claimIndicator.drop(columns = ['SUBTYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Preprocessing Columns ######################################\n",
    "cc_exposure.rename(columns={'ID':'EXPOSUREID'}, inplace=True)\n",
    "cc_exposure.rename(columns={'CLAIMANTDENORMID':'CONTACTID'}, inplace=True)\n",
    "cc_claim.rename(columns={'ID':'CLAIMID'}, inplace=True)\n",
    "cc_transaction.rename(columns={'ID':'TRANSACTIONID'}, inplace=True)\n",
    "cc_contact.rename(columns={'ID':'CONTACTID'}, inplace=True)\n",
    "cc_claimcontact.rename(columns={'ID':'CLAIMCONTACTID'}, inplace=True)\n",
    "cc_address.rename(columns={'ID':'ADDRESSID'}, inplace=True)\n",
    "cc_policy.rename(columns={'ID':'POLICYID'}, inplace=True)\n",
    "cctl_losscause.rename(columns={'ID':'LOSSCAUSE'}, inplace=True)\n",
    "cctl_losscause.rename(columns={'DESCRIPTION':'LOSSDESCRIPTION'}, inplace=True)\n",
    "cc_user.rename(columns={'ID':'USERID'}, inplace=True)\n",
    "cctl_userexperiencetype.rename(columns = {'NAME' : 'ADJUSTOR_EXPERIENCE'},\n",
    "                               inplace=True)\n",
    "cc_check.rename(columns={'ID':'CHECKID'}, inplace=True)\n",
    "cc_catastrophe.rename(columns={'ID':'CATASTROPHEID'}, inplace=True)\n",
    "cc_catastrophe.rename(columns={'TYPE':'CATASTROPHETYPEID'}, inplace=True)\n",
    "cctl_catastrophetype.rename(columns={'ID':'CATASTROPHETYPEID'}, inplace=True)\n",
    "cctl_catastrophetype.rename(columns={'NAME':'CATASTROPHETYPE'}, inplace=True)\n",
    "cc_catastrophezone.rename(columns={'ID':'CATASTROPHEZONEID'}, inplace=True)\n",
    "cc_catastrophezone.rename(columns={'ZONETYPE':'ZONETYPEID'}, inplace=True)\n",
    "cctl_zonetype.rename(columns={'ID':'ZONETYPEID'}, inplace=True)\n",
    "cctl_zonetype.rename(columns={'NAME':'ZONETYPE'}, inplace=True)\n",
    "\n",
    "\n",
    "cc_address = column_preprocess(cc_address, ['ADDRESSLINE1'])\n",
    "cc_check = column_preprocess(cc_check, ['PAYTO'])\n",
    "cc_contact = column_preprocess(cc_contact,['FIRSTNAME', 'LASTNAME', 'NAME'])\n",
    "\n",
    "cc_transaction['CREATETIME'] = pd.to_datetime(cc_transaction[\"CREATETIME\"])\n",
    "cc_activity['CREATETIME'] = pd.to_datetime(cc_activity[\"CREATETIME\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Merge Data Tables ##########################################\n",
    "loss_address = cc_address.copy()\n",
    "loss_address.columns = ['LOSS_' + str(col) for col in loss_address.columns]\n",
    "cc_claim = cc_claim.merge(loss_address, 'left', \n",
    "                          left_on = 'LOSSLOCATIONID', \n",
    "                          right_on = 'LOSS_ADDRESSID')\n",
    "del loss_address\n",
    "cc_claim = cc_claim.merge(cc_policy, 'left')\n",
    "cc_claim = cc_claim.merge(cc_claimIndicator, 'left') \n",
    "\n",
    "freq = Counter(cc_claim['ISON'])\n",
    "cc_claim['ISON'] = cc_claim['ISON'].astype(float)\n",
    "cc_claim['ISON'] = np.where(np.isnan(cc_claim['ISON']), 0, cc_claim['ISON'])\n",
    "\n",
    "del cc_address, cc_policy, cc_claimIndicator\n",
    "\n",
    "cc_check = cc_check.merge(cc_claimcontact, 'left')\n",
    "cc_check = cc_check.merge(cc_claim[['CLAIMID', 'ASSIGNEDUSERID','LOSSCAUSE',\n",
    "                                    'LOSS_POSTALCODE', 'CATASTROPHEID']], 'left')\n",
    "cc_check = cc_check.merge(cctl_losscause, 'left')\n",
    "cc_check = cc_check.merge(cc_contact[['CONTACTID', 'FIRSTNAME', \n",
    "                                      'LASTNAME', 'NAME', 'ADDRESSBOOKUID']], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'High': 2381, 'Mid': 9, 'Low': 12})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Last Assigned Approval #########################################\n",
    "cc_activity = cc_activity.sort_values('CREATETIME', ascending = False)\n",
    "cc_activity_last = cc_activity.groupby('CLAIMID', as_index = False).first()\n",
    "\n",
    "cc_check = cc_check.merge(cc_activity_last[['CLAIMID', 'UPDATEUSERID']], 'left')\n",
    "cc_check['LastAssignedUser'] = np.where(np.isnan(cc_check['UPDATEUSERID']), \n",
    "        cc_check['ASSIGNEDUSERID'],\n",
    "        cc_check['UPDATEUSERID'])\n",
    "\n",
    "cc_check = cc_check.merge(cc_user, 'left', left_on = 'LastAssignedUser',\n",
    "                          right_on = 'USERID')\n",
    "cc_check = cc_check.merge(cctl_userexperiencetype, 'left', \n",
    "                          left_on = 'EXPERIENCELEVEL', \n",
    "                          right_on = 'ID')\n",
    "\n",
    "cc_claim = cc_claim.merge(cc_activity_last[['CLAIMID', 'UPDATEUSERID']], 'left')\n",
    "cc_claim['LastAssignedUser'] = np.where(np.isnan(cc_claim['UPDATEUSERID']), \n",
    "        cc_claim['ASSIGNEDUSERID'],\n",
    "        cc_claim['UPDATEUSERID'])\n",
    "\n",
    "cc_claim = cc_claim.merge(cc_user, 'left', left_on = 'LastAssignedUser',\n",
    "                          right_on = 'USERID')\n",
    "cc_claim = cc_claim.merge(cctl_userexperiencetype, 'left', \n",
    "                          left_on = 'EXPERIENCELEVEL', \n",
    "                          right_on = 'ID')\n",
    "\n",
    "Counter(cc_claim['ADJUSTOR_EXPERIENCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Useful Tables ############################################\n",
    "claim_payment = cc_check.groupby('CLAIMID', as_index= False).\\\n",
    "    agg({'REPORTABLEAMOUNT' : 'sum'})\n",
    "claim_payment.rename(columns={'REPORTABLEAMOUNT':'ClaimPayment'}, \n",
    "                     inplace=True)\n",
    "\n",
    "cc_claim = cc_claim.merge(claim_payment, 'left')\n",
    "cc_claim['ClaimPayment'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# TAX ID  Merge ###################################################\n",
    "cc_checkpayee = cc_checkpayee.merge(cc_contact, 'inner',\n",
    "                                    left_on = 'PAYEEDENORMID',\n",
    "                                    right_on = 'CONTACTID')\n",
    "\n",
    "Counter(cc_checkpayee['ADDRESSBOOKUID'])\n",
    "\n",
    "cc_checkpayee['VendorIndicator'] = np.where(pd.isna(cc_checkpayee['ADDRESSBOOKUID']), 0, 1)\n",
    "Counter(cc_checkpayee['VendorIndicator'])\n",
    "\n",
    "vendor_dat = cc_checkpayee.loc[cc_checkpayee['VendorIndicator'] == 1]\n",
    "vendor_dat.columns = ['VENDOR_' + str(col) for col in vendor_dat.columns]\n",
    "\n",
    "vendor_dat['VENDOR_CHECKID'].nunique()\n",
    "\n",
    "\n",
    "cc_check = cc_check.merge(vendor_dat, 'left',\n",
    "                          left_on = 'CHECKID',\n",
    "                          right_on = 'VENDOR_CHECKID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Number of approvals for each claim ######################\n",
    "\n",
    "approvals_dat = cc_activity.groupby('CLAIMID', as_index = False).\\\n",
    "    agg({'UPDATEUSERID': 'nunique'})\n",
    "approvals_dat.rename(columns={'UPDATEUSERID':'NumApprovals'}, inplace=True)\n",
    "\n",
    "cc_claim = cc_claim.merge(approvals_dat, 'left')\n",
    "cc_claim['NumApprovals'].fillna(0, inplace = True) \n",
    " \n",
    "approvals_summary = cc_claim.groupby('NumApprovals', as_index = False).\\\n",
    "    agg({'CLAIMID' : 'nunique', 'ClaimPayment' : 'sum'})\n",
    "    \n",
    "approvals_summary.rename(columns={'CLAIMID':'NumClaims', \n",
    "                                  'ClaimPayment' : 'Payment'}, \n",
    "                         inplace=True)\n",
    "approvals_summary = approvals_summary.sort_values('NumApprovals', ascending = True)\n",
    "\n",
    "approvals_summary['NumApprovals'] = np.where(approvals_summary['NumApprovals'] >=3,\n",
    "                 3, approvals_summary['NumApprovals'])\n",
    "approvals_summary['NumApprovals'] = approvals_summary['NumApprovals'].astype(int).astype(str)\n",
    "approvals_summary['NumApprovals'] = np.where(approvals_summary['NumApprovals'] == \"3\",\n",
    "                 \">=3\", approvals_summary['NumApprovals'])\n",
    "\n",
    "approvals_summary = approvals_summary.groupby('NumApprovals', as_index = False).\\\n",
    "    agg({'NumClaims' :'sum', 'Payment' : 'sum'})\n",
    "\n",
    "approvals_summary['Avg_Payment'] = approvals_summary['Payment']/approvals_summary['NumClaims']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Miglani/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  Visualization : Distribution of Number of Approvals \n",
    "labels = approvals_summary['NumApprovals']\n",
    "values = approvals_summary['NumClaims']\n",
    "colors = ['#FEBFB3', '#E1396C', '#96D38C', '#D0F9B1']\n",
    "\n",
    "trace = go.Pie(labels=labels, values=values,\n",
    "              hoverinfo='value', textinfo='percent', sort = False,\n",
    "              textfont=dict(size=20),\n",
    "              marker=dict(colors=colors, \n",
    "                          line=dict(color='#000000', width=2)))\n",
    "\n",
    "data = [trace]\n",
    "layout = Layout(\n",
    "   title = \"Distribution of Number of Approvals\",\n",
    "   showlegend=True,\n",
    "   height=600,\n",
    "   width=600\n",
    ")\n",
    "\n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot(data, filename='Distribution of Number of Approvals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Miglani/10.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Visulaization Dollar\n",
    "labels = approvals_summary['NumApprovals']\n",
    "values = approvals_summary['Payment']\n",
    "colors = ['#FEBFB3', '#E1396C', '#96D38C', '#D0F9B1']\n",
    "\n",
    "trace = go.Pie(labels=labels, values=values,\n",
    "              hoverinfo='value', textinfo='percent', sort = False,\n",
    "              textfont=dict(size=20),\n",
    "              marker=dict(colors=colors, \n",
    "                          line=dict(color='#000000', width=2)))\n",
    "\n",
    "data = [trace]\n",
    "layout = Layout(\n",
    "   title = \"Distribution of Number of Approvals (Dolarwise) \",\n",
    "   showlegend=True,\n",
    "   height=600,\n",
    "   width=600\n",
    ")\n",
    "\n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot(data, filename='Distribution of Number of Approvals (Dolarwise) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Fraud Scenerio 3 : Manual Cheque Fraud ###############\n",
    "\n",
    "### Need to do by adjustor level : #####################################\n",
    "### Compare the manual payment across adjustors (identify outliers)\n",
    "\n",
    "\n",
    "approval_mthd_pymt = cc_check.groupby(['LastAssignedUser','PAYMENTMETHOD'], \n",
    "                                 as_index= False).\\\n",
    "                                 agg({'REPORTABLEAMOUNT' : 'sum'})\n",
    "\n",
    "approval_pymt = cc_check.groupby(['LastAssignedUser'], \n",
    "                                 as_index= False).\\\n",
    "                                 agg({'REPORTABLEAMOUNT' : 'sum'})                                 \n",
    "approval_pymt.rename(columns={'REPORTABLEAMOUNT':'Ttl_REPORTABLEAMOUNT'}, \n",
    "                     inplace=True)\n",
    "\n",
    "approval_mthd_pymt['Manual_Check_Amt'] = np.where(\\\n",
    "                  approval_mthd_pymt['PAYMENTMETHOD']== 1, \n",
    "                  approval_mthd_pymt['REPORTABLEAMOUNT'], 0)\n",
    "\n",
    "approval_manual_pymt = approval_mthd_pymt.groupby('LastAssignedUser',\n",
    "                                                  as_index = False).\\\n",
    "                                                  agg({'Manual_Check_Amt' : 'sum'})\n",
    "                                                  \n",
    "approval_manual_pymt = approval_manual_pymt.merge(approval_pymt, 'left')                                                  \n",
    "                                                  \n",
    "\n",
    "approval_manual_pymt['PercentageManual'] = \\\n",
    "    100 * approval_manual_pymt['Manual_Check_Amt'] / approval_manual_pymt['Ttl_REPORTABLEAMOUNT']\n",
    "    \n",
    "#approval_manual_pymt.to_csv(intermediate_dir_path + \"Visualization/Test_manual_check.csv\", \n",
    "#                   encoding='utf-8', index=False)\n",
    "\n",
    "Thresold_Perc_Manual_Payment = np.mean(approval_manual_pymt['PercentageManual']) + \\\n",
    "    np.std(approval_manual_pymt['PercentageManual'])\n",
    "\n",
    "# approval_manual_pymt = approval_manual_pymt.loc[approval_manual_pymt['PercentageManual'] \\\n",
    "#                                                 > Thresold_Perc_Manual_Payment]\n",
    "\n",
    "f3_claim = cc_claim.merge(approval_manual_pymt, 'inner')\n",
    "\n",
    "del Thresold_Perc_Manual_Payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Miglani/12.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Visulaization\n",
    "trace = go.Histogram(\n",
    "   x=approval_manual_pymt['PercentageManual'],\n",
    "   xbins = dict(start=0,end=25,size=5),\n",
    "   autobinx = False, \n",
    "   marker = dict(color='#EB89B5'),\n",
    "   opacity=0.75\n",
    ")\n",
    "data = [trace]\n",
    "layout = Layout(\n",
    "   title = \"Manual Check Percentage\",\n",
    "   showlegend=False,\n",
    "   height=600,\n",
    "   width=600\n",
    ")\n",
    "\n",
    "py.iplot(data, filename='Manual Check Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Fraud 5 : Adjustor Overpaying for certain cause ##############\n",
    "\n",
    "\n",
    "cause_pymt = cc_check.groupby('LOSSCAUSE', \n",
    "                              as_index = False).\\\n",
    "                              agg({'REPORTABLEAMOUNT' : ['mean', 'std']})                         \n",
    "cause_pymt.columns = ['LOSSCAUSE', 'Mean_Payment', 'Std_Payment']\n",
    "\n",
    "cc_check = cc_check.merge(cause_pymt, 'left') \n",
    "\n",
    "cc_check['Cause_Thresold'] = cc_check['Mean_Payment'] + \\\n",
    "    num_std_dev * cc_check['Std_Payment']\n",
    "    \n",
    "f5_check = cc_check.copy()\n",
    "f5_check['ExtraThresold'] = f5_check['REPORTABLEAMOUNT'] - \\\n",
    "    f5_check['Cause_Thresold']\n",
    "    \n",
    "f5_check['ExtraThresold'] = np.where(f5_check['ExtraThresold'] > 0,\n",
    "        f5_check['ExtraThresold'], 0)\n",
    "\n",
    "f5_summary = f5_check.groupby('LOSSDESCRIPTION', as_index = False).\\\n",
    "    agg({'ExtraThresold':'sum', 'REPORTABLEAMOUNT' : 'sum'})\n",
    "    \n",
    "f5_summary['ExcessPaidAmt'] = 100 * \\\n",
    "    f5_summary['ExtraThresold']/ f5_summary['REPORTABLEAMOUNT']\n",
    "\n",
    "f5_summary = f5_summary.sort_values('ExcessPaidAmt', ascending = False) #order the reserves\n",
    "\n",
    "#f5_summary.to_csv(intermediate_dir_path + \"Visualization/Pekin_cause_extra_3sd.csv\", \n",
    "#                   encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##  Visualization \n",
    "# trace = go.Bar(x = f5_summary['LOSSDESCRIPTION'],\n",
    "#              y = f5_summary['ExcessPaidAmt'])\n",
    "         \n",
    "\n",
    "# data = [trace]\n",
    "# layout = Layout(title = \"Cause v/s Extra Payment Done\",\n",
    "#                height=600, width=600,)\n",
    "\n",
    "# fig = dict( data=data, layout=layout )\n",
    "\n",
    "# py.iplot(data, filename='Cause v/s Extra Payment Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Adjustor - Vendor Pair ########################################\n",
    "cc_check.columns.values\n",
    "\n",
    "## Fuzzy Match\n",
    "adjustor_payto = cc_check.groupby(['LastAssignedUser'], \n",
    "                                  as_index = False).\\\n",
    "                                  agg({'PAYTO' : 'unique'})                                  \n",
    "adjustor_payto.rename(columns={'PAYTO':'all_PAYTO'}, inplace=True)\n",
    "adjustor_payto['all_PAYTO'] = adjustor_payto['all_PAYTO'].astype(tuple)\n",
    "\n",
    "\n",
    "pair_adjustor_receiver = cc_check.groupby(['LastAssignedUser', 'PAYTO'], \n",
    "                                          as_index = False).\\\n",
    "                                          agg({'REPORTABLEAMOUNT' : 'sum', \n",
    "                                               'CLAIMID' : 'nunique'})\n",
    "\n",
    "pair_adjustor_receiver = pair_adjustor_receiver.merge(adjustor_payto)\n",
    "\n",
    "pair_adjustor_receiver['FuzzyPayTo'] = ''\n",
    "pair_adjustor_receiver['FuzzyPayToScore'] = np.nan\n",
    "\n",
    "pair_adjustor_receiver['Replaced_With'] = ''\n",
    "x = 1\n",
    "\n",
    "\n",
    "\n",
    "for x in range(len(pair_adjustor_receiver.index)) :\n",
    "    pay_to = pair_adjustor_receiver['PAYTO'][x]\n",
    "    pay_to_same_adjustor = pair_adjustor_receiver['all_PAYTO'][x]\n",
    "    temp = process.extract(pay_to, pay_to_same_adjustor,\n",
    "                           scorer = fuzz.token_sort_ratio)\n",
    "    if (len(temp) > 1):\n",
    "        temp = temp[1]\n",
    "        pair_adjustor_receiver.loc[x, 'FuzzyPayTo'] = temp[0]\n",
    "        pair_adjustor_receiver.loc[x, 'FuzzyPayToScore'] = temp[1]\n",
    "        \n",
    "Thresold_fuzzy = 83\n",
    "fuzzy_pair = pair_adjustor_receiver.loc[pair_adjustor_receiver['FuzzyPayToScore'] >= \\\n",
    "                                        Thresold_fuzzy]\n",
    "\n",
    "fuzzy_pair = fuzzy_pair[['PAYTO', 'FuzzyPayTo']]\n",
    "fuzzy_pair['Replace_With'] = None\n",
    "x = 38\n",
    "replaced_with = []\n",
    "for x in fuzzy_pair.index :\n",
    "    if (fuzzy_pair['PAYTO'][x] not in replaced_with) :\n",
    "        fuzzy_pair.loc[x, 'Replace_With'] = fuzzy_pair['FuzzyPayTo'][x]\n",
    "        replaced_with.append(fuzzy_pair['FuzzyPayTo'][x])\n",
    "        \n",
    "fuzzy_pair = fuzzy_pair[['PAYTO', 'Replace_With']]\n",
    "fuzzy_pair = fuzzy_pair.loc[~pd.isna(fuzzy_pair['Replace_With'])]\n",
    "\n",
    "cc_check_fuzzy = cc_check.merge(fuzzy_pair,'left')\n",
    "cc_check_fuzzy['PAYTO'] = np.where(pd.isna(cc_check_fuzzy['Replace_With']),\n",
    "              cc_check_fuzzy['PAYTO'], cc_check_fuzzy['Replace_With'])\n",
    "\n",
    "f1_adj_ven = cc_check_fuzzy.groupby(['LOSS_POSTALCODE','LOSSCAUSE', \n",
    "                               'ADJUSTOR_EXPERIENCE', 'LastAssignedUser', \n",
    "                               'PAYTO'], as_index = False).\\\n",
    "                               agg({'REPORTABLEAMOUNT' : 'sum',\n",
    "                                    'CLAIMID' : 'nunique'})\n",
    "f1_adj_ven.rename(columns={'CLAIMID':'Num_Claims'}, inplace=True)\n",
    "\n",
    "f1_ven = cc_check.groupby(['LOSS_POSTALCODE','LOSSCAUSE', \n",
    "                               'PAYTO'], as_index = False).\\\n",
    "                               agg({'REPORTABLEAMOUNT' : 'sum',\n",
    "                                    'CLAIMID' : 'nunique'})\n",
    "f1_ven.rename(columns={'CLAIMID':'Num_Claims_Vendor'}, inplace=True)\n",
    "f1_ven.rename(columns={'REPORTABLEAMOUNT':'REPORTABLEAMOUNT_Vendor'}, inplace=True)\n",
    "\n",
    "f1_adj_ven = f1_adj_ven.merge(f1_ven)\n",
    "\n",
    "f1_adj_ven['Perc_Amount'] = 100 * \\\n",
    "    f1_adj_ven['REPORTABLEAMOUNT'] / f1_adj_ven['REPORTABLEAMOUNT_Vendor']\n",
    "\n",
    "f1_adj_ven['Perc_Freq'] = 100 * \\\n",
    "    f1_adj_ven['Num_Claims'] / f1_adj_ven['Num_Claims_Vendor']\n",
    "    \n",
    "## Reliability Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Auhoriser History ###########################################\n",
    "    \n",
    "f7_adj = cc_claim.groupby('LastAssignedUser', as_index = False).\\\n",
    "    agg({'ISON' : 'sum', 'CLAIMID' : 'nunique'})\n",
    "\n",
    "f7_adj['PercFraud'] = f7_adj['ISON']/f7_adj['CLAIMID']\n",
    "\n",
    "f7_adj = f7_adj.sort_values('PercFraud', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Catastrophe ###################################################\n",
    "\n",
    "cc_claim_catastrophe = cc_claim.loc[~pd.isna(cc_claim['CATASTROPHEID'])]\n",
    "cc_claim_catastrophe = cc_claim_catastrophe.merge(cc_catastrophe, 'left')  \n",
    "\n",
    "\n",
    "cc_check_catastrophe = cc_check.merge(cc_catastrophe, 'inner')\n",
    "\n",
    "##Adjustor Overpaying for certain cause in catastrophe\n",
    "\n",
    "\n",
    "cause_pymt = cc_check_catastrophe.groupby([ 'CATASTROPHEID', 'LOSSCAUSE'], \n",
    "                              as_index = False).\\\n",
    "                              agg({'REPORTABLEAMOUNT' : ['mean', 'std']})  \n",
    "                              \n",
    "cause_pymt.columns = ['CATASTROPHEID' , 'LOSSCAUSE', 'Mean_Payment', 'Std_Payment']\n",
    "\n",
    "cc_check_catastrophe = cc_check_catastrophe.merge(cause_pymt, 'left') \n",
    "\n",
    "cc_check_catastrophe['Cause_Thresold'] = cc_check_catastrophe['Mean_Payment'] + \\\n",
    "    num_std_dev * cc_check_catastrophe['Std_Payment']\n",
    "    \n",
    "f8_check = cc_check_catastrophe.copy()\n",
    "f8_check.columns.values\n",
    "f8_check['ExtraThresold'] = f8_check['REPORTABLEAMOUNT'] - \\\n",
    "    f8_check['Cause_Thresold']\n",
    "    \n",
    "f8_check['ExtraThresold'] = np.where(f8_check['ExtraThresold'] > 0,\n",
    "        f8_check['ExtraThresold'], 0)\n",
    "\n",
    "f8_summary = f8_check.groupby(['CATASTROPHEID','LOSSCAUSE'], as_index = False).\\\n",
    "    agg({'ExtraThresold':'sum', 'REPORTABLEAMOUNT' : 'sum'})\n",
    "    \n",
    "f8_summary['ExcessPaidAmt'] = 100 * \\\n",
    "    f8_summary['ExtraThresold']/ f8_summary['REPORTABLEAMOUNT']\n",
    "\n",
    "f8_summary = f8_summary.sort_values('ExcessPaidAmt', ascending = False) #order the reserves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
